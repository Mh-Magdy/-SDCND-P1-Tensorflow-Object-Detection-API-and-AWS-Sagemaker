{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e1cd147",
   "metadata": {},
   "source": [
    "# (Project Write-up) Tensorflow Object Detection API and AWS Sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7c881e",
   "metadata": {},
   "source": [
    "# Model 1 - EfficientDet D1 640x640 (Starter Code)\n",
    "\n",
    "\n",
    "### Model Performance\n",
    "The model was evaluated using various metrics:\n",
    "- Overall mAP\t`0.080`.\n",
    "- DetectionBoxes Precision (mAP)** at different thresholds, with scores ranging from `0.03` to `0.2`.\n",
    "- DetectionBoxes Recall** across multiple recall metrics (e.g., AR@1, AR@10, AR@100).\n",
    "- The overall mAP values indicate that the model struggles to accurately detect objects, especially small ones.\n",
    "\n",
    "### Training vs. Validation Loss\n",
    "- The **Training Loss** decreased steadily, indicating effective learning from the training data.\n",
    "- However, the **Validation Loss** began to increase towards the end, suggesting overfitting as the model starts to memorize training patterns rather than generalize.\n",
    "\n",
    "### Observed Behavior and Improvements\n",
    "This behavior is expected when models overfit or when the dataset does not adequately cover the problem domain. To improve performance:\n",
    "1. **Data Augmentation** to increase dataset diversity.\n",
    "2. **Regularization** (e.g., dropout, weight decay) to combat overfitting.\n",
    "3. **Hyperparameter Tuning** to find an optimal setup.\n",
    "4. Consider **simplifying or enhancing model complexity** based on observed underfitting or overfitting.\n",
    "\n",
    "### Best Model Suggestion\n",
    "At this stage, no model performs optimally. Refining hyperparameters, using transfer learning, or increasing data quantity could improve results.\n",
    "\n",
    "### TensorBoard\n",
    "![1](train_eval/m1/imgs/1.png)\n",
    "![2](train_eval/m1/imgs/2.png)\n",
    "![3](train_eval/m1/imgs/3.png)\n",
    "![4](train_eval/m1/imgs/4.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c349fa33",
   "metadata": {},
   "source": [
    "# Model 2 - EfficientDet D1 640x640 (Improving optimizer and Data Augmentation)\n",
    "\n",
    "### Model Performance and Optimization Changes\n",
    "After optimizing several hyperparameters, the following changes were observed:\n",
    "- **Learning Rate**: Increased the base learning rate to 0.1 for potentially faster convergence.\n",
    "- **Total Steps**: Set to 350,000 to allow extended training with gradual decay, aiming for better generalization.\n",
    "- **Warmup Parameters**: Reduced `warmup_learning_rate` to 0.0005 and increased `warmup_steps` to 5000 for smoother initial training.\n",
    "- **Momentum**: Raised `momentum_optimizer_value` to 0.95 for enhanced stability in training.\n",
    "- **Moving Average**: Enabled moving average to smooth model convergence further.\n",
    "\n",
    "### Results\n",
    "The optimized model showed the following performance metrics:\n",
    "- **mAP (mean Average Precision)** across categories:\n",
    "  - mAP@0.5IOU: `~0.25`\n",
    "  - mAP@0.75IOU: `~0.08`\n",
    "  - Precision for small, medium, and large objects ranged from `0.03` to `0.35`.\n",
    "- **Recall** improved for larger objects but remained lower for smaller detections.\n",
    "\n",
    "### Training vs. Validation Loss\n",
    "- **Training Loss** continued to decrease, showcasing learning progress.\n",
    "- **Validation Loss** showed a more stable trend post-optimization, with a smaller gap compared to training loss, suggesting reduced overfitting.\n",
    "  \n",
    "### Expected Behavior\n",
    "This reduction in the gap between training and validation loss aligns with expectations for smoother, more generalized training. With the added steps, momentum, and moving average, the model has stabilized, as seen in smoother loss curves.\n",
    "\n",
    "### Suggestions for Further Improvement\n",
    "1. **Data Augmentation**: Further increase data diversity for smaller object detection.\n",
    "2. **Experiment with Dropout**: Add dropout layers to reduce overfitting.\n",
    "3. **Increase Batch Size**: A higher batch size could stabilize gradients, especially beneficial with increased momentum.\n",
    "4. **Hyperparameter Tuning**: Further fine-tune learning rates, decay schedules, and optimizer parameters to balance performance for all object sizes.\n",
    "\n",
    "### Best Model Recommendation\n",
    "The optimized model is currently the best version. However, incorporating additional data or using a pre-trained model could yield even better results, especially for smaller objects.\n",
    "\n",
    "### TensorBoard\n",
    "![1](train_eval/m2/imgs/1.png)\n",
    "![2](train_eval/m2/imgs/2.png)\n",
    "![3](train_eval/m2/imgs/3.png)\n",
    "![4](train_eval/m2/imgs/4.png)\n",
    "![5](train_eval/m2/imgs/5.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb88960",
   "metadata": {},
   "source": [
    "# Model 3 - SSD ResNet50 V1 FPN 640x640 (RetinaNet50)\t\n",
    "\n",
    "### Model Performance\n",
    "The second model (Model 3) was trained and evaluated, resulting in the following performance metrics:\n",
    "- **mAP (mean Average Precision)**:\n",
    "  - mAP overall: `0.0837`\n",
    "  - mAP for large objects: `0.2447`\n",
    "  - mAP for medium objects: `0.278`\n",
    "  - mAP for small objects: `0.038`\n",
    "  - mAP@0.5IOU: `0.1797`\n",
    "  - mAP@0.75IOU: `0.0706`\n",
    "  \n",
    "- **Recall** values indicated improvement in detecting larger objects with AR@100 reaching `0.2827` for large objects, while smaller objects maintained lower recall scores.\n",
    "\n",
    "### Training vs. Validation Loss\n",
    "- **Training Loss**: Continued to decrease smoothly, indicating steady learning.\n",
    "- **Validation Loss**: Showed stability, though a slight increase was observed at certain points, suggesting minor overfitting but with a manageable gap relative to training loss.\n",
    "\n",
    "### Observed Behavior\n",
    "The increased mAP for medium and large objects indicates that Model 3 performs better on larger objects than smaller ones, consistent with lower recall and precision for small objects. The validation loss trend reflects a model that could still benefit from further regularization and fine-tuning, especially for small-object detection.\n",
    "\n",
    "### Recommendations for Improvement\n",
    "1. **Further Regularization**: Employ dropout or weight decay to reduce overfitting.\n",
    "2. **Augment Data for Small Objects**: Introduce more small-object variations in the training dataset to improve detection performance.\n",
    "3. **Parameter Tuning**: Adjust learning rates or use a more gradual learning rate decay to explore more stable convergence.\n",
    "\n",
    "### Conclusion\n",
    "Model 3 shows improvement in detection of medium and large objects, but its performance on small objects remains low. Further fine-tuning and targeted data augmentation could help improve its generalization.\n",
    "\n",
    "### TensorBoard\n",
    "![1](train_eval/m3/imgs/1.png)\n",
    "![2](train_eval/m3/imgs/2.png)\n",
    "![3](train_eval/m3/imgs/3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433d7199",
   "metadata": {},
   "source": [
    "#  Model 4  - Faster R-CNN ResNet152 V1 640x640\t\n",
    "\n",
    "### Model Performance\n",
    "The third model (Model 4) achieved the following results across various metrics:\n",
    "- **mAP (mean Average Precision)**:\n",
    "  - Overall mAP: `0.1144`\n",
    "  - Large objects: `0.6913`\n",
    "  - Medium objects: `0.4021`\n",
    "  - Small objects: `0.0491`\n",
    "  - mAP@0.5IOU: `0.2303`\n",
    "  - mAP@0.75IOU: `0.0977`\n",
    "\n",
    "- **Recall** values:\n",
    "  - The model performed well on large and medium objects, with AR@100 for large objects reaching `0.7050` and medium objects `0.4836`.\n",
    "  - Small objects had lower recall, with AR@100 for small objects at `0.0832`.\n",
    "\n",
    "### Training vs. Validation Loss\n",
    "- **Classification Loss** and **Localization Loss** showed decreasing trends, indicating the model is learning from the data.\n",
    "- **Total Loss** stabilized over time, although it maintained a slightly higher value, which could suggest the model might be struggling with complex classes or smaller objects.\n",
    "\n",
    "### Observed Behavior\n",
    "The model's higher performance on large and medium objects compared to small ones aligns with expectations, given the generally lower mAP and recall for small object detection. The learning rate progression shows a smooth increase and plateau, contributing to stable convergence in losses over time. The object detection visualizations demonstrate accurate bounding boxes and labels for large and medium-sized objects, with some successful detections for smaller objects.\n",
    "\n",
    "### Recommendations for Improvement\n",
    "1. **Data Augmentation for Small Objects**: Increase small-object variety in the training data to boost detection performance.\n",
    "2. **Hyperparameter Tuning**: Experiment with lower learning rates or slower decay to improve small-object recognition.\n",
    "3. **Regularization Techniques**: Add dropout or weight decay to prevent overfitting on large and medium objects.\n",
    "\n",
    "### Conclusion\n",
    "Model 4 displays robust performance for large and medium object detection, while small object performance remains an area for improvement. The model could benefit from additional data augmentation and fine-tuning, particularly to enhance recall and precision for smaller objects.\n",
    "\n",
    "### TensorBoard\n",
    "![1](train_eval/m4/imgs/1.png)\n",
    "![2](train_eval/m4/imgs/2.png)\n",
    "![3](train_eval/m4/imgs/3.png)\n",
    "![4](train_eval/m4/imgs/4.png)\n",
    "![5](train_eval/m4/imgs/5.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f99cb7",
   "metadata": {},
   "source": [
    "## Model Comparison Summary\n",
    "\n",
    "Below is a comparison of the four models based on mean Average Precision (mAP), recall, and other relevant metrics to identify the best-performing model.\n",
    "\n",
    "| Metric                      | Model 1   | Model 2   | Model 3   | Model 4   |\n",
    "|-----------------------------|-----------|-----------|-----------|-----------|\n",
    "| **Overall mAP**             | 0.080     | 0.084     | 0.0837    | **0.1144** |\n",
    "| **mAP for Large Objects**   | 0.25      | 0.6913    | 0.2447    | **0.6913** |\n",
    "| **mAP for Medium Objects**  | -         | 0.4021    | 0.278     | **0.4021** |\n",
    "| **mAP for Small Objects**   | -         | 0.0491    | 0.038     | **0.0491** |\n",
    "| **mAP@0.5 IOU**             | 0.18      | 0.2303    | 0.1797    | **0.2303** |\n",
    "| **mAP@0.75 IOU**            | 0.07      | 0.0977    | 0.0706    | **0.0977** |\n",
    "| **AR@1**                    | -         | 0.0279    | 0.0215    | **0.0279** |\n",
    "| **AR@10**                   | -         | 0.1189    | 0.0881    | **0.1189** |\n",
    "| **AR@100 (Large)**          | 0.2827    | 0.7050    | -         | **0.7050** |\n",
    "| **AR@100 (Medium)**         | 0.3466    | 0.4836    | -         | **0.4836** |\n",
    "| **AR@100 (Small)**          | 0.0875    | 0.0832    | -         | **0.0832** |\n",
    "\n",
    "### Summary of Findings\n",
    "- **Model 4** outperforms Models 1, 2, and 3 across nearly all metrics, with the highest overall mAP (0.1144) and strong performance in precision and recall for large and medium objects.\n",
    "- **Model 1** has the lowest performance, particularly in mAP for all object sizes.\n",
    "- **Model 2** (previously Model 3’s data) performs slightly better than Model 3 (previously Model 2’s data) in most metrics but falls short of Model 4.\n",
    "\n",
    "### Conclusion\n",
    "**Model 4** is the best-performing model based on mAP and recall scores, especially for larger and medium-sized objects. Future improvements could focus on augmenting data for small objects and applying further regularization techniques to enhance performance in small-object detection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7a03f9",
   "metadata": {},
   "source": [
    "# Augmentation inside pipeline.config. used in models 2,3 and 4\n",
    "\n",
    "```\n",
    "data_augmentation_options {\n",
    "    random_scale_crop_and_pad_to_square {\n",
    "      output_size: 640\n",
    "      scale_min: 0.10000000149011612\n",
    "      scale_max: 2.0\n",
    "    }\n",
    "  }\n",
    "  data_augmentation_options {\n",
    "    random_crop_image {\n",
    "      min_object_covered: 0.0\n",
    "      min_aspect_ratio: 0.75\n",
    "      max_aspect_ratio: 3.0\n",
    "      min_area: 0.75\n",
    "      max_area: 1.0\n",
    "      overlap_thresh: 0.0\n",
    "    }\n",
    "  }\n",
    "  data_augmentation_options {\n",
    "   random_adjust_brightness {\n",
    "     max_delta: 0.2\n",
    "   }\n",
    "  }\n",
    "data_augmentation_options {\n",
    "  random_adjust_contrast {\n",
    "    min_delta: 0.8\n",
    "    max_delta: 1.25\n",
    "  }\n",
    " }\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2f0e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
